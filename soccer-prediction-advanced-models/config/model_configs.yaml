model_configs:
  xgboost:
    n_estimators: 100
    learning_rate: 0.1
    max_depth: 6
    min_child_weight: 1
    gamma: 0
    subsample: 0.8
    colsample_bytree: 0.8
    objective: 'reg:squarederror'
    eval_metric: 'rmse'
  
  lightgbm:
    n_estimators: 100
    learning_rate: 0.1
    max_depth: -1
    num_leaves: 31
    min_data_in_leaf: 20
    objective: 'regression'
    metric: 'rmse'
  
  neural_network:
    input_dim: 20  # Adjust based on feature size
    hidden_layers:
      - units: 64
        activation: 'relu'
      - units: 32
        activation: 'relu'
    output_dim: 3  # Adjust based on number of target variables
    loss: 'mean_squared_error'
    optimizer: 'adam'
    metrics:
      - 'mae'