{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c37475c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soccerdata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "34ed0b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://sofifa.com/players?type=all&lg%5B0%5D=13&lg%5B1%5D=31&lg%5B2%5D=19&lg%5B3%5D=53&lg%5B4%5D=16&showCol%5B0%5D=ae&showCol%5B1%5D=oa&showCol%5B2%5D=pt&showCol%5B3%5D=vl&showCol%5B4%5D=wg&showCol%5B5%5D=tt&showCol%5B6%5D=pi&showCol%5B7%5D=wi&showCol%5B8%5D=pf&showCol%5B9%5D=bo&showCol%5B10%5D=hi&showCol%5B11%5D=bp&showCol%5B12%5D=jt&showCol%5B13%5D=le&showCol%5B14%5D=gu&showCol%5B15%5D=rc&showCol%5B16%5D=cp&showCol%5B17%5D=at&showCol%5B18%5D=ps2&showCol%5B19%5D=ps1&showCol%5B20%5D=t2&showCol%5B21%5D=t1&showCol%5B22%5D=phy&showCol%5B23%5D=def&showCol%5B24%5D=pas&showCol%5B25%5D=pac&showCol%5B26%5D=dri&showCol%5B27%5D=hc&showCol%5B28%5D=bt&showCol%5B29%5D=ir&showCol%5B30%5D=aw&showCol%5B31%5D=sk&showCol%5B32%5D=dw&showCol%5B33%5D=bs&showCol%5B34%5D=sho&showCol%5B35%5D=gd&showCol%5B36%5D=sa&showCol%5B37%5D=td&showCol%5B38%5D=cj&showCol%5B39%5D=wk&showCol%5B40%5D=tc&showCol%5B41%5D=ma&showCol%5B42%5D=cm&showCol%5B43%5D=vi&showCol%5B44%5D=pe&showCol%5B45%5D=in&showCol%5B46%5D=ar&showCol%5B47%5D=po&showCol%5B48%5D=te&showCol%5B49%5D=st&showCol%5B50%5D=ju&showCol%5B51%5D=so&showCol%5B52%5D=tp&showCol%5B53%5D=sr&showCol%5B54%5D=ln&showCol%5B55%5D=ag&showCol%5B56%5D=ba&showCol%5B57%5D=re&showCol%5B58%5D=ac&showCol%5B59%5D=to&showCol%5B60%5D=sp&showCol%5B61%5D=lo&showCol%5B62%5D=cu&showCol%5B63%5D=dr&showCol%5B64%5D=fr&showCol%5B65%5D=ts&showCol%5B66%5D=he&showCol%5B67%5D=fi&showCol%5B68%5D=ta&showCol%5B69%5D=sh&showCol%5B70%5D=cr&showCol%5B71%5D=vo&showCol%5B72%5D=bl&count=100&r=240050&offset=60\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "404a3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = {\n",
    "    2025: \"250044\",\n",
    "    2024: \"240050\",\n",
    "    2023: \"230054\",\n",
    "    2022: \"220069\",\n",
    "    2021: \"210064\",\n",
    "    2020: \"200061\",\n",
    "    2019: \"190075\",\n",
    "    2018: \"180084\",\n",
    "    2017: \"170099\",\n",
    "    2016: \"160058\",\n",
    "    2015: \"150059\",\n",
    "    2014: \"140052\", \n",
    "    2013: \"130034\",\n",
    "    2012: \"120002\",\n",
    "    2011: \"110002\",\n",
    "    2010: \"100002\",\n",
    "    2009: \"090002\",\n",
    "    2008: \"080002\",\n",
    "    2007: \"070002\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df5fb2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf646593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "chrome_options = Options()\n",
    "\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "\n",
    "# Add user agent\n",
    "chrome_options.add_argument('user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')\n",
    "\n",
    "# Performance optimizations\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "chrome_options.add_argument('--disable-extensions')\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "print(\"Chrome WebDriver initialized\")\n",
    "\n",
    "# Define save path\n",
    "SAVE_DIR = Path(\"../data/raw/raw_sofifa/yearly\")\n",
    "\n",
    "def get_team_stats(driver, season_code, year):\n",
    "    \"\"\"\n",
    "    Scrape team stats for a given season and offset.\n",
    "    Driver should be passed in to reuse across multiple calls.\n",
    "    \"\"\"\n",
    "    from selenium.common.exceptions import TimeoutException\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    offset = 0\n",
    "    while True:\n",
    "        try:\n",
    "            driver.get(f\"{base_url}&r={season_code}&offset={offset}\")\n",
    "            print(f\"Season C: {season_code}, Offset: {offset} - Page loaded\")\n",
    "        \n",
    "            time.sleep(3)\n",
    "            \n",
    "            WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, \"table\"))\n",
    "            )\n",
    "            \n",
    "        except TimeoutException:\n",
    "            print(f\"No more data found at offset {offset}. Scraping complete!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "            break\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        table = soup.find('table')  # Find first table\n",
    "        \n",
    "        if not table:\n",
    "            print(\"ERROR: No table found!\")\n",
    "            break\n",
    "        \n",
    "        headers = [th.get_text(strip=True) for th in table.select(\"thead th\")]\n",
    "        \n",
    "        data = []\n",
    "        for row in table.select(\"tbody tr\"):\n",
    "            cols = row.find_all(['th', 'td'])\n",
    "            if cols:\n",
    "                data.append([col.get_text(strip=True) for col in cols])\n",
    "\n",
    "        temp_df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "        offset += 60\n",
    "        df = pd.concat([df, temp_df], ignore_index=True)\n",
    "        \n",
    "        if offset % 600 == 0:\n",
    "            print(f\"{offset} number of players collected so far...\")\n",
    "        \n",
    "    df['season'] = year\n",
    "    df['season_code'] = season_code\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Total rows collected: {len(df)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    return df\n",
    "\n",
    "for year, season_code in seasons.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Starting scrape for year {year} (season code: {season_code})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    df = get_team_stats(driver, season_code, year)\n",
    "    output_path = SAVE_DIR / f\"sofifa_players_{year}.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"{year} Data Saved to: {output_path}\")\n",
    "\n",
    "\n",
    "print(f\"\\nScraping complete! DataFrame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "# def collect_all(self):\n",
    "    #     \"\"\"Combine all yearly CSV files into one master file.\"\"\"\n",
    "    #     df_list = []\n",
    "        \n",
    "    #     for year in self.seasons.keys():\n",
    "    #         file_path = self.save_dir / f\"sofifa_players_{year}.csv\"\n",
    "    #         if file_path.exists():\n",
    "    #             yearly_df = pd.read_csv(file_path)\n",
    "    #             df_list.append(yearly_df)\n",
    "    #         else:\n",
    "    #             print(f\"Warning: {file_path} not found, skipping...\")\n",
    "        \n",
    "    #     # Combine all DataFrames at once\n",
    "    #     df = pd.concat(df_list, ignore_index=True)\n",
    "        \n",
    "    #     output_path = self.save_dir.parent / \"sofifa_players_all_years.csv\"\n",
    "    #     df.to_csv(output_path, index=False)\n",
    "        \n",
    "    #     print(f\"All years combined ({len(df)} rows) and saved to: {output_path}\")\n",
    "\n",
    "\n",
    "    # def yearly_scrape(self):\n",
    "    #     \"\"\"Scrape all seasons and save individual year files.\"\"\"\n",
    "    #     # Ensure directory exists\n",
    "    #     self.save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    #     driver = self.initialize_driver()\n",
    "        \n",
    "    #     try:\n",
    "    #         for year, season_code in self.seasons.items():\n",
    "    #             print(f\"\\n{'='*60}\")\n",
    "    #             print(f\"Starting year {year} (season code: {season_code})\")\n",
    "    #             print(f\"{'='*60}\")\n",
    "                \n",
    "    #             df = self.get_individual_stats(driver, season_code, year)\n",
    "    #             output_path = self.save_dir / f\"sofifa_players_{year}.csv\"\n",
    "    #             df.to_csv(output_path, index=False)\n",
    "    #             print(f\"âœ“ {year} data saved to: {output_path}\\n\")\n",
    "            \n",
    "        \n",
    "    #     finally:\n",
    "    #         # Always close driver, even if error occurs\n",
    "    #         self.close_driver(driver)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
